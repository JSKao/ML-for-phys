{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine\n",
    "Dataset and code by Giacomo Torlai, Juan Carrasquilla and Lauren Hayward Sierens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Goal`: This code will train a Restricted Boltzmann Machine (RBM) to learn the\n",
    "distribution of spin configurations of the 2D Ising model at a\n",
    "given temperature. After training, we will generate states from this trained model. Finally, we'll use these new states to calculate energy, magnetization, specific heat and susceptibility and compare them to those in Monte Carlo result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What's given`:  20000 states for each of 11 different temperatures (1.0, 1.254, 1.508, 1.762, 2.016, 2.269, 2.524, 2.778, 3.032, 3.286 and 3.54) generated by MCMC from Boltzmann distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import itertools as it\n",
    "from rbm import RBM\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify font sizes for plots:\n",
    "plt.rcParams['axes.labelsize']  = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['xtick.labelsize'] = 8\n",
    "plt.rcParams['ytick.labelsize'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters:\n",
    "L                   = 4       #linear size of the system\n",
    "T                   = 2.269   #a temperature for which there are MC configurations stored in Data_ising2d/MC_results\n",
    "num_visible         = L*L     #number of visible nodes\n",
    "num_hidden          = 4       #number of hidden nodes\n",
    "nsteps              = 30000   #number of training steps (iterations over the mini-batches)\n",
    "learning_rate_start = 1e-3    #the learning rate will start at this value and decay exponentially\n",
    "bsize               = 100     #batch size\n",
    "num_gibbs           = 10      #number of Gibbs iterations (steps of contrastive divergence)\n",
    "num_samples         = 10      #number of chains in PCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save weights and biases to a parameter file ###\n",
    "def save_parameters(sess, rbm):\n",
    "    weights, visible_bias, hidden_bias = sess.run([rbm.weights, rbm.visible_bias, rbm.hidden_bias])\n",
    "    \n",
    "    parameter_dir = 'Data_ising2d/RBM_parameters'\n",
    "    if not(os.path.isdir(parameter_dir)):\n",
    "      os.mkdir(parameter_dir)\n",
    "    parameter_file_path =  '%s/parameters_nH%d_L%d' %(parameter_dir,num_hidden,L)\n",
    "    parameter_file_path += '_T' + str(T)\n",
    "    np.savez_compressed(parameter_file_path, weights=weights, visible_bias=visible_bias, hidden_bias=hidden_bias)\n",
    "\n",
    "class Placeholders(object):\n",
    "    pass\n",
    "\n",
    "class Ops(object):\n",
    "    pass\n",
    "\n",
    "weights      = None  #weights\n",
    "visible_bias = None  #visible bias\n",
    "hidden_bias  = None  #hidden bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MC configuration training data:\n",
    "trainFileName = 'Data_ising2d/MC_results/ising2d_L'+str(L)+'_T'+str(T)+'_train.txt'\n",
    "xtrain        = np.loadtxt(trainFileName)\n",
    "testFileName  = 'Data_ising2d/MC_results/ising2d_L'+str(L)+'_T'+str(T)+'_test.txt'\n",
    "xtest         = np.loadtxt(testFileName)\n",
    "\n",
    "xtrain_randomized = np.random.permutation(xtrain) # random permutation of training data\n",
    "xtest_randomized  = np.random.permutation(xtest) # random permutation of test data\n",
    "iterations_per_epoch = xtrain.shape[0] / bsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_local_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.local_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RBM class\n",
    "rbm = RBM(num_hidden=num_hidden, num_visible=num_visible, weights=weights, visible_bias=visible_bias,hidden_bias=hidden_bias, num_samples=num_samples) \n",
    "\n",
    "# Initialize operations and placeholders classes\n",
    "ops          = Ops()\n",
    "placeholders = Placeholders()\n",
    "placeholders.visible_samples = tf.placeholder(tf.float32, shape=(None, num_visible), name='v') # placeholder for training data\n",
    "\n",
    "total_iterations = 0 # starts at zero \n",
    "ops.global_step  = tf.Variable(total_iterations, name='global_step_count', trainable=False)\n",
    "learning_rate    = tf.train.exponential_decay(\n",
    "    learning_rate_start,\n",
    "    ops.global_step,\n",
    "    100 * xtrain.shape[0]/bsize,\n",
    "    1.0 # decay rate = 1 means no decay\n",
    ")\n",
    "  \n",
    "cost      = rbm.neg_log_likelihood_forGrad(placeholders.visible_samples, num_gibbs=num_gibbs)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, epsilon=1e-2)\n",
    "ops.lr    = learning_rate\n",
    "ops.train = optimizer.minimize(cost, global_step=ops.global_step)\n",
    "ops.init  = tf.group(tf.initialize_all_variables(), tf.initialize_local_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Nsteps = 200, NLL on test data = 11.042135\n",
      "Epoch = 1, Nsteps = 400, NLL on test data = 10.859882\n",
      "Epoch = 2, Nsteps = 600, NLL on test data = 10.559417\n",
      "Epoch = 3, Nsteps = 800, NLL on test data = 10.297823\n",
      "Epoch = 4, Nsteps = 1000, NLL on test data = 10.047187\n",
      "Epoch = 5, Nsteps = 1200, NLL on test data = 9.783507\n",
      "Epoch = 6, Nsteps = 1400, NLL on test data = 9.499597\n",
      "Epoch = 7, Nsteps = 1600, NLL on test data = 9.197001\n",
      "Epoch = 8, Nsteps = 1800, NLL on test data = 8.872510\n",
      "Epoch = 9, Nsteps = 2000, NLL on test data = 8.536477\n",
      "Epoch = 10, Nsteps = 2200, NLL on test data = 8.191921\n",
      "Epoch = 11, Nsteps = 2400, NLL on test data = 7.833353\n",
      "Epoch = 12, Nsteps = 2600, NLL on test data = 7.473599\n",
      "Epoch = 13, Nsteps = 2800, NLL on test data = 7.116506\n",
      "Epoch = 14, Nsteps = 3000, NLL on test data = 6.767595\n",
      "Epoch = 15, Nsteps = 3200, NLL on test data = 6.429122\n",
      "Epoch = 16, Nsteps = 3400, NLL on test data = 6.099010\n",
      "Epoch = 17, Nsteps = 3600, NLL on test data = 5.792073\n",
      "Epoch = 18, Nsteps = 3800, NLL on test data = 5.506166\n",
      "Epoch = 19, Nsteps = 4000, NLL on test data = 5.246628\n",
      "Epoch = 20, Nsteps = 4200, NLL on test data = 5.017650\n",
      "Epoch = 21, Nsteps = 4400, NLL on test data = 4.786785\n",
      "Epoch = 22, Nsteps = 4600, NLL on test data = 4.598628\n",
      "Epoch = 23, Nsteps = 4800, NLL on test data = 4.401643\n",
      "Epoch = 24, Nsteps = 5000, NLL on test data = 4.239531\n",
      "Epoch = 25, Nsteps = 5200, NLL on test data = 4.081813\n",
      "Epoch = 26, Nsteps = 5400, NLL on test data = 3.951239\n",
      "Epoch = 27, Nsteps = 5600, NLL on test data = 3.849337\n",
      "Epoch = 28, Nsteps = 5800, NLL on test data = 3.704218\n",
      "Epoch = 29, Nsteps = 6000, NLL on test data = 3.576317\n",
      "Epoch = 30, Nsteps = 6200, NLL on test data = 3.585489\n",
      "Epoch = 31, Nsteps = 6400, NLL on test data = 3.398014\n",
      "Epoch = 32, Nsteps = 6600, NLL on test data = 3.338243\n",
      "Epoch = 33, Nsteps = 6800, NLL on test data = 3.196968\n",
      "Epoch = 34, Nsteps = 7000, NLL on test data = 3.175227\n",
      "Epoch = 35, Nsteps = 7200, NLL on test data = 3.053942\n",
      "Epoch = 36, Nsteps = 7400, NLL on test data = 3.066659\n",
      "Epoch = 37, Nsteps = 7600, NLL on test data = 3.100456\n",
      "Epoch = 38, Nsteps = 7800, NLL on test data = 2.831403\n",
      "Epoch = 39, Nsteps = 8000, NLL on test data = 2.767339\n",
      "Epoch = 40, Nsteps = 8200, NLL on test data = 2.989120\n",
      "Epoch = 41, Nsteps = 8400, NLL on test data = 2.695072\n",
      "Epoch = 42, Nsteps = 8600, NLL on test data = 2.661057\n",
      "Epoch = 43, Nsteps = 8800, NLL on test data = 4.708335\n",
      "Epoch = 44, Nsteps = 9000, NLL on test data = 3.243497\n",
      "Epoch = 45, Nsteps = 9200, NLL on test data = 3.057669\n",
      "Epoch = 46, Nsteps = 9400, NLL on test data = 5.694174\n",
      "Epoch = 47, Nsteps = 9600, NLL on test data = 4.990290\n",
      "Epoch = 48, Nsteps = 9800, NLL on test data = 2.543685\n",
      "Epoch = 49, Nsteps = 10000, NLL on test data = 2.862159\n",
      "Epoch = 50, Nsteps = 10200, NLL on test data = 2.644675\n",
      "Epoch = 51, Nsteps = 10400, NLL on test data = 2.392704\n",
      "Epoch = 52, Nsteps = 10600, NLL on test data = 2.241585\n",
      "Epoch = 53, Nsteps = 10800, NLL on test data = 2.181490\n",
      "Epoch = 54, Nsteps = 11000, NLL on test data = 2.212822\n",
      "Epoch = 55, Nsteps = 11200, NLL on test data = 2.445627\n",
      "Epoch = 56, Nsteps = 11400, NLL on test data = 2.440614\n",
      "Epoch = 57, Nsteps = 11600, NLL on test data = 6.126779\n",
      "Epoch = 58, Nsteps = 11800, NLL on test data = 7.278771\n",
      "Epoch = 59, Nsteps = 12000, NLL on test data = 3.362354\n",
      "Epoch = 60, Nsteps = 12200, NLL on test data = 3.833420\n",
      "Epoch = 61, Nsteps = 12400, NLL on test data = 3.668193\n",
      "Epoch = 62, Nsteps = 12600, NLL on test data = 9.054284\n",
      "Epoch = 63, Nsteps = 12800, NLL on test data = 13.039590\n",
      "Epoch = 64, Nsteps = 13000, NLL on test data = 9.499654\n",
      "Epoch = 65, Nsteps = 13200, NLL on test data = 5.534205\n",
      "Epoch = 66, Nsteps = 13400, NLL on test data = 1.888162\n",
      "Epoch = 67, Nsteps = 13600, NLL on test data = 3.477766\n",
      "Epoch = 68, Nsteps = 13800, NLL on test data = 3.938036\n",
      "Epoch = 69, Nsteps = 14000, NLL on test data = 8.791416\n",
      "Epoch = 70, Nsteps = 14200, NLL on test data = 12.044257\n",
      "Epoch = 71, Nsteps = 14400, NLL on test data = 11.549060\n",
      "Epoch = 72, Nsteps = 14600, NLL on test data = 9.665719\n",
      "Epoch = 73, Nsteps = 14800, NLL on test data = 7.628303\n",
      "Epoch = 74, Nsteps = 15000, NLL on test data = 5.825440\n",
      "Epoch = 75, Nsteps = 15200, NLL on test data = 4.133461\n",
      "Epoch = 76, Nsteps = 15400, NLL on test data = 2.655007\n",
      "Epoch = 77, Nsteps = 15600, NLL on test data = 1.823956\n",
      "Epoch = 78, Nsteps = 15800, NLL on test data = 2.072036\n",
      "Epoch = 79, Nsteps = 16000, NLL on test data = 2.806623\n",
      "Epoch = 80, Nsteps = 16200, NLL on test data = 1.696013\n",
      "Epoch = 81, Nsteps = 16400, NLL on test data = 2.894839\n",
      "Epoch = 82, Nsteps = 16600, NLL on test data = 4.113375\n",
      "Epoch = 83, Nsteps = 16800, NLL on test data = 5.121058\n",
      "Epoch = 84, Nsteps = 17000, NLL on test data = 6.278690\n",
      "Epoch = 85, Nsteps = 17200, NLL on test data = 7.394516\n",
      "Epoch = 86, Nsteps = 17400, NLL on test data = 8.148656\n",
      "Epoch = 87, Nsteps = 17600, NLL on test data = 8.957668\n",
      "Epoch = 88, Nsteps = 17800, NLL on test data = 9.694296\n",
      "Epoch = 89, Nsteps = 18000, NLL on test data = 10.485029\n",
      "Epoch = 90, Nsteps = 18200, NLL on test data = 11.206861\n",
      "Epoch = 91, Nsteps = 18400, NLL on test data = 11.723847\n",
      "Epoch = 92, Nsteps = 18600, NLL on test data = 12.362662\n",
      "Epoch = 93, Nsteps = 18800, NLL on test data = 12.765372\n",
      "Epoch = 94, Nsteps = 19000, NLL on test data = 13.339753\n",
      "Epoch = 95, Nsteps = 19200, NLL on test data = 14.165149\n",
      "Epoch = 96, Nsteps = 19400, NLL on test data = 9.976468\n",
      "Epoch = 97, Nsteps = 19600, NLL on test data = 2.554863\n",
      "Epoch = 98, Nsteps = 19800, NLL on test data = 4.415739\n",
      "Epoch = 99, Nsteps = 20000, NLL on test data = 2.558839\n",
      "Epoch = 100, Nsteps = 20200, NLL on test data = 1.466201\n",
      "Epoch = 101, Nsteps = 20400, NLL on test data = 2.223976\n",
      "Epoch = 102, Nsteps = 20600, NLL on test data = 3.376621\n",
      "Epoch = 103, Nsteps = 20800, NLL on test data = 4.572061\n",
      "Epoch = 104, Nsteps = 21000, NLL on test data = 5.587083\n",
      "Epoch = 105, Nsteps = 21200, NLL on test data = 6.412295\n",
      "Epoch = 106, Nsteps = 21400, NLL on test data = 7.317032\n",
      "Epoch = 107, Nsteps = 21600, NLL on test data = 7.936508\n",
      "Epoch = 108, Nsteps = 21800, NLL on test data = 8.681978\n",
      "Epoch = 109, Nsteps = 22000, NLL on test data = 9.352604\n",
      "Epoch = 110, Nsteps = 22200, NLL on test data = 10.035456\n",
      "Epoch = 111, Nsteps = 22400, NLL on test data = 10.595263\n",
      "Epoch = 112, Nsteps = 22600, NLL on test data = 11.170745\n",
      "Epoch = 113, Nsteps = 22800, NLL on test data = 11.655618\n",
      "Epoch = 114, Nsteps = 23000, NLL on test data = 12.193071\n",
      "Epoch = 115, Nsteps = 23200, NLL on test data = 12.650158\n",
      "Epoch = 116, Nsteps = 23400, NLL on test data = 13.299671\n",
      "Epoch = 117, Nsteps = 23600, NLL on test data = 13.648764\n",
      "Epoch = 118, Nsteps = 23800, NLL on test data = 13.791741\n",
      "Epoch = 119, Nsteps = 24000, NLL on test data = 14.223278\n",
      "Epoch = 120, Nsteps = 24200, NLL on test data = 14.515127\n",
      "Epoch = 121, Nsteps = 24400, NLL on test data = 15.096352\n",
      "Epoch = 122, Nsteps = 24600, NLL on test data = 15.210475\n",
      "Epoch = 123, Nsteps = 24800, NLL on test data = 15.665688\n",
      "Epoch = 124, Nsteps = 25000, NLL on test data = 15.939378\n",
      "Epoch = 125, Nsteps = 25200, NLL on test data = 16.173962\n",
      "Epoch = 126, Nsteps = 25400, NLL on test data = 16.484766\n",
      "Epoch = 127, Nsteps = 25600, NLL on test data = 16.775164\n",
      "Epoch = 128, Nsteps = 25800, NLL on test data = 16.903339\n",
      "Epoch = 129, Nsteps = 26000, NLL on test data = 17.133579\n",
      "Epoch = 130, Nsteps = 26200, NLL on test data = 17.597269\n",
      "Epoch = 131, Nsteps = 26400, NLL on test data = 17.730053\n",
      "Epoch = 132, Nsteps = 26600, NLL on test data = 18.193785\n",
      "Epoch = 133, Nsteps = 26800, NLL on test data = 18.051300\n",
      "Epoch = 134, Nsteps = 27000, NLL on test data = 18.475771\n",
      "Epoch = 135, Nsteps = 27200, NLL on test data = 17.307005\n",
      "Epoch = 136, Nsteps = 27400, NLL on test data = 10.821665\n",
      "Epoch = 137, Nsteps = 27600, NLL on test data = 5.832062\n",
      "Epoch = 138, Nsteps = 27800, NLL on test data = 2.043138\n",
      "Epoch = 139, Nsteps = 28000, NLL on test data = 2.505196\n",
      "Epoch = 140, Nsteps = 28200, NLL on test data = 5.003828\n",
      "Epoch = 141, Nsteps = 28400, NLL on test data = 4.994212\n",
      "Epoch = 142, Nsteps = 28600, NLL on test data = 1.966183\n",
      "Epoch = 143, Nsteps = 28800, NLL on test data = 6.681145\n",
      "Epoch = 144, Nsteps = 29000, NLL on test data = 11.081314\n",
      "Epoch = 145, Nsteps = 29200, NLL on test data = 15.404645\n",
      "Epoch = 146, Nsteps = 29400, NLL on test data = 19.798941\n",
      "Epoch = 147, Nsteps = 29600, NLL on test data = 23.949684\n",
      "Epoch = 148, Nsteps = 29800, NLL on test data = 27.183016\n",
      "Epoch = 149, Nsteps = 30000, NLL on test data = 27.070168\n"
     ]
    }
   ],
   "source": [
    "# Define the negative log-likelihood\n",
    "# We can use this to plot the RBM's training progress.\n",
    "# This calculation is intractable for large networks so let's only do it for small num_hidden\n",
    "logZ = rbm.exact_log_partition_function()\n",
    "placeholders.logZ = tf.placeholder(tf.float32)\n",
    "NLL = rbm.neg_log_likelihood(placeholders.visible_samples,placeholders.logZ)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(ops.init)\n",
    "  \n",
    "bcount         = 0  #counter\n",
    "epochs_done    = 0  #epochs counter\n",
    "nll_test_list  = [] #negative log-likelihood for each epoch\n",
    "nll_train_list = [] #negative log-likelihood for each epoch\n",
    "for ii in range(nsteps):\n",
    "    if bcount*bsize+ bsize>=xtrain.shape[0]:\n",
    "        bcount = 0\n",
    "        xtrain_randomized = np.random.permutation(xtrain)\n",
    "\n",
    "    batch     =  xtrain_randomized[ bcount*bsize: bcount*bsize+ bsize,:]\n",
    "    bcount    += 1\n",
    "    feed_dict =  {placeholders.visible_samples: batch}\n",
    "\n",
    "    _, num_steps = sess.run([ops.train, ops.global_step], feed_dict=feed_dict)\n",
    "\n",
    "    if num_steps % iterations_per_epoch == 0:\n",
    "        lz = sess.run(logZ)\n",
    "        nll_test = sess.run(NLL,feed_dict={placeholders.visible_samples: xtest_randomized, placeholders.logZ: lz})\n",
    "        nll_test_list.append(nll_test)\n",
    "    \n",
    "        print ('Epoch = %d, Nsteps = %d, NLL on test data = %.6f' %(epochs_done,num_steps,nll_test))\n",
    "        save_parameters(sess, rbm)\n",
    "        epochs_done += 1\n",
    "\n",
    "        ## Update the plot:\n",
    "        #plt.figure(1)\n",
    "        #plt.clf()\n",
    "        #plt.plot( np.arange(epochs_done), nll_test_list, 'o-')\n",
    "        #plt.xlabel('Epoch')\n",
    "        #plt.ylabel('NLL')\n",
    "        #plt.pause(0.1)\n",
    "\n",
    "#plt.savefig('NLL_vs_epoch_T%s.pdf' %(str(T)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can now sample spin configurations from the trained RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temperature list for which there are trained RBM parameters stored in Data_ising2d/RBM_parameters\n",
    "#T_list = [1.0,1.254,1.508,1.762,2.016,2.269,2.524,2.778,3.032,3.286,3.540]\n",
    "T_list = [2.269]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling parameters:\n",
    "num_samples  = 500  # how many independent chains will be sampled\n",
    "gibb_updates = 2    # how many gibbs updates per call to the gibbs sampler\n",
    "nbins        = 100  # number of calls to the RBM sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify where the sampled configurations will be stored:\n",
    "samples_dir = 'Data_ising2d/RBM_samples'\n",
    "if not(os.path.isdir(samples_dir)):\n",
    "  os.mkdir(samples_dir)\n",
    "samples_filePaths = [] #file paths where samples for each T will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the RBM for each temperature in T_list:\n",
    "rbms           = []\n",
    "rbm_samples    = []\n",
    "for i in range(len(T_list)):\n",
    "  T = T_list[i]\n",
    "  \n",
    "  samples_filePath =  '%s/samples_nH%d_L%d' %(samples_dir,num_hidden,L)\n",
    "  samples_filePath += '_T' + str(T) + '.txt'\n",
    "  samples_filePaths.append(samples_filePath)\n",
    "  fout = open(samples_filePath,'w')\n",
    "  fout.close()\n",
    "  \n",
    "  #Read in the trained RBM parameters:\n",
    "  path_to_params =  'Data_ising2d/RBM_parameters/parameters_nH%d_L%d' %(num_hidden,L)\n",
    "  path_to_params += '_T'+str(T)+'.npz'\n",
    "  params         =  np.load(path_to_params)\n",
    "  weights        =  params['weights']\n",
    "  visible_bias   =  params['visible_bias']\n",
    "  hidden_bias    =  params['hidden_bias']\n",
    "  hidden_bias    =  np.reshape(hidden_bias,(hidden_bias.shape[0],1))\n",
    "  visible_bias   =  np.reshape(visible_bias,(visible_bias.shape[0],1))\n",
    "  \n",
    "  # Initialize RBM class\n",
    "  rbms.append(RBM(\n",
    "    num_hidden=num_hidden, num_visible=num_visible,\n",
    "    weights=weights, visible_bias=visible_bias,hidden_bias=hidden_bias,\n",
    "    num_samples=num_samples\n",
    "  ))\n",
    "  rbm_samples.append(rbms[i].stochastic_maximum_likelihood(gibb_updates))\n",
    "#end of loop over temperatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin 0\n",
      "bin 1\n",
      "bin 2\n",
      "bin 3\n",
      "bin 4\n",
      "bin 5\n",
      "bin 6\n",
      "bin 7\n",
      "bin 8\n",
      "bin 9\n",
      "bin 10\n",
      "bin 11\n",
      "bin 12\n",
      "bin 13\n",
      "bin 14\n",
      "bin 15\n",
      "bin 16\n",
      "bin 17\n",
      "bin 18\n",
      "bin 19\n",
      "bin 20\n",
      "bin 21\n",
      "bin 22\n",
      "bin 23\n",
      "bin 24\n",
      "bin 25\n",
      "bin 26\n",
      "bin 27\n",
      "bin 28\n",
      "bin 29\n",
      "bin 30\n",
      "bin 31\n",
      "bin 32\n",
      "bin 33\n",
      "bin 34\n",
      "bin 35\n",
      "bin 36\n",
      "bin 37\n",
      "bin 38\n",
      "bin 39\n",
      "bin 40\n",
      "bin 41\n",
      "bin 42\n",
      "bin 43\n",
      "bin 44\n",
      "bin 45\n",
      "bin 46\n",
      "bin 47\n",
      "bin 48\n",
      "bin 49\n",
      "bin 50\n",
      "bin 51\n",
      "bin 52\n",
      "bin 53\n",
      "bin 54\n",
      "bin 55\n",
      "bin 56\n",
      "bin 57\n",
      "bin 58\n",
      "bin 59\n",
      "bin 60\n",
      "bin 61\n",
      "bin 62\n",
      "bin 63\n",
      "bin 64\n",
      "bin 65\n",
      "bin 66\n",
      "bin 67\n",
      "bin 68\n",
      "bin 69\n",
      "bin 70\n",
      "bin 71\n",
      "bin 72\n",
      "bin 73\n",
      "bin 74\n",
      "bin 75\n",
      "bin 76\n",
      "bin 77\n",
      "bin 78\n",
      "bin 79\n",
      "bin 80\n",
      "bin 81\n",
      "bin 82\n",
      "bin 83\n",
      "bin 84\n",
      "bin 85\n",
      "bin 86\n",
      "bin 87\n",
      "bin 88\n",
      "bin 89\n",
      "bin 90\n",
      "bin 91\n",
      "bin 92\n",
      "bin 93\n",
      "bin 94\n",
      "bin 95\n",
      "bin 96\n",
      "bin 97\n",
      "bin 98\n",
      "bin 99\n"
     ]
    }
   ],
   "source": [
    "# Initialize tensorflow\n",
    "init = tf.group(tf.initialize_all_variables(), tf.initialize_local_variables())\n",
    "\n",
    "# Sample thermodynamic observables:\n",
    "N = num_visible\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "  \n",
    "  for i in range(nbins):\n",
    "    print ('bin %d' %i)\n",
    "\n",
    "    for t in range(len(T_list)):\n",
    "      fout = open(samples_filePaths[t],'a')\n",
    "      \n",
    "      _,samples=sess.run(rbm_samples[t])\n",
    "      spins = np.asarray((2*samples-1)) #convert from 0,1 variables to -1,+1 variables\n",
    "      for k in range(num_samples):\n",
    "        for i in range(N):\n",
    "         fout.write('%d ' %int(spins[k,i]))\n",
    "        fout.write('\\n')\n",
    "      fout.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the new states generated by RBM, calculate the physical observables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleFileName = 'Data_ising2d/RBM_samples/samples_nH%d_L%d' %(num_hidden,L)\n",
    "sampleFileName += '_T' + str(T) + '.txt'\n",
    "xsample        = np.loadtxt(sampleFileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculate energy of the given state of 2D Ising model\n",
    "def neighbor(site):\n",
    "    \n",
    "def energy(state):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
