{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative model - taking RBM for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given dataset X = {x} from some ground truth distribution P(x). Can we learn a p(x) $\\approx P(x)$? This goal is the theme of generative modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easiest method is to build the frequency distribution $P_{X}(x)$ from the dataset X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, we will learn the model p(x) via $P_{X}(x)\\equiv \\frac{1}{|X|}\\sum_{x_{k}}\\delta_{x,x_{k}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this one is not \"generative\". That is, it rely on the full knowledge of dataset X which most of the time doesn't conquer the size of Hilbert space. As a result, $P_{X}(x)$ will not achieve p(x)$\\approx P(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to use dataset X to generate additional knowledge to fulfill the gap between $P_{X}(x)$ and p(x). Once we get this, i.e. $P_{X}(x)\\approx p(x)\\approx P(x)$, we can generate new x' that's not in X very accurately. Accuracy means that x' is well approximately under P(x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, instead of naively using X's frequency distribution $P_{X}(x)$, we try to parametrize a model $p_{\\lambda}(x)$ and assign a suitable cost function to measure the distance between $p_{\\lambda}(x)$ and $P(x)$. Then \"machine learning\" the model $p_{\\lambda}(x)$ to approach to $P(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter $\\lambda$ plays the same role in generative model as W, b in neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To model or parametrize a probability distribution, the tool of graphical model is useful however in this lab we won't discuss the detail of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the earliest parametrization of probability is the energy-based one called $\\bf{\\text{Hopfield model}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\lambda}(x)=\\frac{1}{Z}e^{-E(x)}$ where E(x)= -<x|W|x>-<b|x> , $\\lambda$={W,b}, and Z=$\\sum_{x}e^{-E(x)}$ is partition funtion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This representation of probability distribution is highly general in sense that the \"interaction\" of features of x is fully connected. This can be seen by the <x|W|x> term that different features all appear in the sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generalized version is $\\bf{\\text{Boltzmann Machine(BM)}}$, which adds hidden units h together with x fully connected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While BM extends the expression capacity, it's still not a feasible training model. However, its simplified version is. Removal of inter-layer connection of BM allows the model trainable. This version is called \n",
    "$\\bf{\\text{Restricted Boltzmann Machine(RBM)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"energy\" of RBM is $E(x,h) = -\\sum_{i,j}^{n_{x},n_{h}}W_{ij}x_{i}h_{j}-\\sum_{i}^{n_{x}}b_{i}x_{i}-\\sum_{i}^{n_{h}}c_{i}h_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $n_{x}$ and $n_{h}$ are the numbers of physical unit and hidden unit respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we want to train $p_{\\lambda}(x)=\\sum_{h}p_{\\lambda}(x,h) = \\frac{1}{Z}\\sum_{h}e^{-E(x,h)}$ to approach $P(x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember what we did in neural network for supervised learning. We want to train AL(x) to approach y, so we define cost function of these two guy, such as r.m.s. or cross-entropy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need a cost function for two probability guys $p_{\\lambda}(x,h)$ and $P(x)$. The candidate is Kullback-Leibler divergence $D(P|p_{\\lambda})=\\sum_{x}P(x)log\\frac{P(x)}{p_{\\lambda}(x)}=\\sum_{x}P(x)logP(x)-\\sum_{x}P(x)logp_{\\lambda}(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the cost function in Supervised learning, which measure the distance of two point AL and y in hyperdimensional space. The measure of distance of two probability distribution is taken along the whole value in the hyper-dimentional space.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note in the last equality the first term is independent of the model we're training. It's in some sense the entropy of dataset(since the summation is over data values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like what we do in supervised learning, after defining the model, all the rest things belong to the dataset X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have dataset X in hand, and its frequency distribution $P_{X}(x)\\equiv \\frac{1}{|X|}\\sum_{x_{k}}\\delta_{x,x_{k}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximate this to $P(x)$ in KL divergence, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$D\\approx -H_{X} - \\frac{1}{|X|}\\sum_{x_{k}} logp_{\\lambda}(x_{k})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first term as we just mentioned is independent of model. We pick the second term as our new cost function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C_{\\lambda} = -\\frac{1}{|X|}\\sum_{x_{k}}logp_{\\lambda}(x_{k})$, with gradient descent $\\lambda \\Longrightarrow \\lambda-\\eta\\nabla_{\\lambda} C_{\\lambda}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KL divergence works for any probability model. Now we plug in the model of our interst , RBM, to $p_{\\lambda}(x)$  for a single data $x_{j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$logp_{\\lambda}(x_{j})= log\\frac{1}{Z}\\sum_{h}e^{-E(x,h)}= log\\sum_{h}e^{-E(x,h)}-logZ = log\\sum_{h}e^{-E(x,h)}- log\\sum_{x,h}e^{-E(x,h)}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, the derivations are valid for any energy-based probability model with visible unit x and hidden unit h."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial logp_{\\lambda}(x_{j})}{\\partial\\lambda} = \\frac{\\partial}{\\partial\\lambda}(log\\sum_{h}e^{-E})-\\frac{\\partial}{\\partial\\lambda}(log\\sum_{x,h}e^{-E}) \\\\ \\\\ = \\frac{-1}{\\sum_{h}e^{-E}}\\sum_{h}e^{-E}\\frac{\\partial E}{\\partial\\lambda}+\\frac{1}{\\sum_{x,h}e^{-E}}\\sum_{x,h}e^{-E}\\frac{\\partial E}{\\partial\\lambda}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This equation can be simplified by a probability identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\lambda}(h|x)=\\frac{p(x,h)}{p(x)}=\\frac{\\frac{1}{Z}e^{-E}}{\\frac{1}{Z}\\sum_{h}e^{-E}}=\\frac{e^{-E}}{\\sum_{h}e^{-E}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert to the above equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial logp_{\\lambda}(x_{j})}{\\partial\\lambda} = \\sum_{h}p_{\\lambda}(h|x)\\frac{\\partial E}{\\partial\\lambda}+\\frac{1}{\\sum_{x,h}e^{-E}}\\sum_{x,h}e^{-E}\\frac{\\partial E}{\\partial\\lambda} = \\sum_{h}p_{\\lambda}(h|x)\\frac{\\partial E}{\\partial\\lambda}+\\sum_{x,h}p_{\\lambda}(x,h)\\frac{\\partial E}{\\partial\\lambda}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that first term involves summation over hidden units, while second term is still full expectation value (sum over x and h)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the advantage of RBM manifests itself in conditional probability calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\lambda}(h|x)=\\Pi_{i} p_{\\lambda}(h_{i}|x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\lambda}(x|h)=\\Pi_{i} p_{\\lambda}(x_{i}|h)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since all units are probabilistic independent in the same layer as the definition of RBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leads to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial logp_{\\lambda}(x_{j})}{\\partial\\lambda} = \\sum_{h}\\Pi_{i}p_{\\lambda}(h_{i}|x)\\frac{\\partial E}{\\partial\\lambda}+\\sum_{x,h}p_{\\lambda}(x)p_{\\lambda}(h|x)\\frac{\\partial E}{\\partial\\lambda}\\\\\n",
    "= \\sum_{h}\\Pi_{i}p_{\\lambda}(h_{i}|x)\\frac{\\partial E}{\\partial\\lambda}+\\sum_{x}p_{\\lambda}(x)\\sum_{h}p_{\\lambda}(h|x)\\frac{\\partial E}{\\partial\\lambda} \\\\\n",
    "=\\sum_{h}\\Pi_{i}p_{\\lambda}(h_{i}|x)\\frac{\\partial E}{\\partial\\lambda}+\\sum_{x}p_{\\lambda}(x)\\sum_{h}\\Pi_{i}p_{\\lambda}(h_{i}|x)\\frac{\\partial E}{\\partial\\lambda}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summation over h can be analytically solved by the following result(check this result), where the first result is used in this case. (We will do it later when we discuss gibbs sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(h_{j}=1|x) = sigmoid(\\sum_{i} (w_{ij}x_{i}+c_{i})) \\\\ \\\\ \n",
    "p(x_{i}=1|h) = sigmoid(\\sum_{j} (w_{ij}h_{j}+c_{j}))$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Summarize what we have so far. We model a RMB probability distribution $p_{\\lambda}(x)$ and apply KL-divergence to measure the distance $D(P(x)|p_{\\lambda}(x))$ where we pick the model dependent term as the cost function $C_{\\lambda} = -\\frac{1}{|X|}\\sum_{x_{k}}logp_{\\lambda}(x_{k})$. Do the gradient inside the summation $\\frac{\\partial logp_{\\lambda}(x_{j})}{\\partial\\lambda}$ with respect to parameter $\\lambda$. Then we obtain two term that first one can be solved analytically and second one is intractable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compactly, what we get is just"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\nabla_{\\lambda}C_{\\lambda}= <\\frac{\\partial E}{\\partial\\lambda}>_{p_{\\lambda}(x|h)} - <\\frac{\\partial E}{\\partial\\lambda}>_{p_{\\lambda}(x,h)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What remaining is to tackle the second term. Notice that it's expectation value of a joint distribution. We can apply Monte Carlo method with some sampling rule to calculate it approximately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take parameter $\\lambda=W_{ij}$, then the second term is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$<x_{i}h_{j}>_{p_{\\lambda}(x,h)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we do some kind of MCMC sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$<x_{i}h_{j}>_{p_{\\lambda}(x,h)} \\approx \\frac{1}{N_{MC}}\\sum_{MCMC} x_{i}h_{j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll discuss the sampling method later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recontruction of quantum states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume the ground truth P(x) is Boltzmann distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(x)=P(\\sigma)=\\frac{1}{Z}e^{-\\beta E(\\sigma)}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the system we deal with is Ising model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H = -\\sum_{<i,j>}\\sigma^{z}_{i}\\sigma^{z}_{j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that x directly represent spin $\\sigma$. This together with the connection of x and h in $p_{\\lambda}(x,h)$ makes RBM is a natural representation of Ising model. Because neighborhood correlation is taken into account by this connection. One \"bond\" $<i,j>$ corresponds to one h."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about quantum states? If our Ising model system is in state $|{\\Psi}>$ and being expanded by basis states as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$|{\\Psi}>=\\sum_{\\sigma}|\\sigma><\\sigma|\\Psi>=\\sum_{\\sigma}\\Psi(\\sigma)|\\sigma> $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our task of unsupervised learning, we need to link probability to the quantum state. It's due to Born, and the probability distribution is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(\\sigma)= |\\Psi(\\sigma)|^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use RBM to represent this distribution as usual, then take the square root of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\lambda}(\\sigma)=\\sum_{h}p_{\\lambda}(\\sigma,h)=|\\psi_{\\lambda}(\\sigma)|^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as $p_{\\lambda}(\\sigma)\\approx P(\\sigma)$, we have $ |\\psi_{\\lambda}(\\sigma)|^{2} \\approx|\\Psi(\\sigma)|^{2} \\Rightarrow \\psi_{\\lambda}(\\sigma) \\approx \\Psi(\\sigma) $, if $|{\\Psi}>$ is real. And thus $|\\psi_{\\lambda}> \\approx |\\Psi>$. Thus, if wavefunction is real, we can directly denote our RBM model of quantum state by $\\psi_{\\lambda}(\\sigma)= \\sqrt{p_{\\lambda}(\\sigma)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model quantum state, we can also obtain the model measurement of observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$<\\hat{O}> \\; \\approx \\; <\\hat{O}>_{\\lambda}\\;= \\;<\\psi_{\\lambda}|\\hat{O}|\\psi_{\\lambda}> \\;= \\; \\sum_{\\sigma\\sigma'}\\psi_{\\lambda}(\\sigma')<\\sigma'|\\hat{O}|\\sigma>\\psi_{\\lambda}(\\sigma) \\\\ \\\\\n",
    "= \\sum_{\\sigma\\sigma'}\\sqrt{p_{\\lambda}(\\sigma')}\\sqrt{p_{\\lambda}(\\sigma)} O_{\\sigma'\\sigma}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This holds when wavefunction is real. But how about complex wavefunction?  Say $\\Psi(\\sigma)=|\\Psi(\\sigma)|e^{i\\phi(\\sigma)}$. As we know, what we want to achieve is RBM model $p_{\\lambda}(\\sigma)$ that approach to $P(\\sigma)$. However, $P(\\sigma)= |\\Psi(\\sigma)|^{2}$ smears out the information of phase $\\phi(\\sigma)$. So we need to additional representation capacity to model the phase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we parametrize the phase by RBM? One way is to let our parameter $\\lambda$ be complex. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is add another RBMs for phase parametrization. We can denote the additional RBM's parameter $\\mu$, and parametrize the complex wavefunction as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Psi_{\\lambda\\mu}(\\sigma)=\\sqrt{p_{\\lambda}(\\sigma)}e^{i\\phi_{\\mu}(\\sigma)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, by the graphical model method, we can just add additional set of hidden units to connect the visible unit via parameter $\\mu$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion about BM family's representational power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of distribution that BM without hidden unit can represent is limited. Since it models only pairwise interaction of variable. One good exercise is to show XOR function cannot be represent by such kind of BM. The rough reason is because XOR function enbody third order correlation while for BM without hidden unit, it's only second order one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we add hidden variable so that the neurons in machine are from x to (x,h) as mentioned above, the representational power increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate explicitly the probability distribution which RBM models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\lambda}(x)=\\sum_{h}p_{\\lambda}(x,h)=\\frac{1}{Z}\\sum_{h}e^{-\\sum_{i,j}W_{ij}x_{i}h_{j}-\\sum_{i}b_{i}x_{i}-\\sum_{i}c_{i}h_{i}}\\\\\n",
    "=\\frac{1}{Z}e^{-\\sum_{i}b_{i}x_{i}}\\sum_{h}e^{-\\sum_{i,j}W_{ij}x_{i}h_{j}-\\sum_{i}c_{i}h_{i}}\n",
    "=\\frac{1}{Z}e^{-\\sum_{i}b_{i}x_{i}}\\sum_{h}e^{-\\sum_{i}(\\sum_{j}W_{ij}x_{j}-c_{i})h_{i}}\\\\\n",
    "=\\frac{1}{Z}e^{-\\sum_{i}b_{i}x_{i}}\\prod_{i=1}^{n_{h}}(\\sum_{h_{i}=0,1}e^{-(\\sum_{j}W_{ij}x_{j}-c_{i})h_{i}})\\\\\n",
    "=\\frac{1}{Z}e^{-\\sum_{i}b_{i}x_{i}}\\prod_{i=1}^{n_{h}}(1+e^{\\sum_{j}W_{ij}x_{j}+c_{i}}) \\\\\n",
    "\\equiv \\frac{1}{Z}e^{\\epsilon_{\\lambda}(x)}\n",
    "$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\epsilon_{\\lambda}(x)\\equiv-\\sum_{j}b_{j}x_{j}-\\sum_{i}log(1+e^{\\sum_{j}W_{ij}x_{j}+c_{i}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, RBM still models a Boltzmann distribution but with a more complex energy functional $\\epsilon_{\\lambda}(x)$ manifest by the nonlinear log term. This term governs the higher older correlation as we can expand it into Taylor series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio $\\frac{n_{h}}{n_{x}}$ essentially measure the representational power of RBM which is better as the ratio is larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a theorem goes to that RBM is an universal representation of any probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in practice as $n_{h}$ is getting large the computational efficiency would be getting worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So an ongoing problem is that can we find another representation that the representational efficiency needs less growing $n_{h}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling technique in RBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewrite and use the result above for the cost function we define earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C_{\\lambda} = -\\frac{1}{|X|}\\sum_{x_{k}}logp_{\\lambda}(x_{k})\\\\\n",
    "=\\frac{1}{|X|}\\sum_{x_{k}}\\epsilon_{\\lambda}(x)+logZ_{\\lambda}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\nabla_{\\lambda}C_{\\lambda}=\\frac{1}{|X|}\\sum_{x_{k}}\\nabla_{\\lambda}\\epsilon_{\\lambda}(x)-\\frac{1}{Z_{\\lambda}}\\sum_{x}e^{-\\epsilon_{\\lambda}(x)}\\nabla_{\\lambda}\\epsilon_{\\lambda}(x) \\\\\n",
    "=<\\nabla_{\\lambda}\\epsilon_{\\lambda}(x)>_{D} - <\\nabla_{\\lambda}\\epsilon_{\\lambda}(x)>_{p_{\\lambda}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS. Compare this to the earlier one to see if the expressions are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term inside the expectation value can be easily derived for parameters W, b and c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial}{\\partial b_{j}}\\epsilon_{\\lambda}(x)= -x_{j}\\\\\n",
    "\\frac{\\partial}{\\partial c_{j}}\\epsilon_{\\lambda}(x)= -\\frac{e^{\\sum_{j}W_{ij}x_{j}+c_{i}}}{1+e^{\\sum_{j}W_{ij}x_{j}+c_{i}}} = - Sigmoid(\\sum_{j}W_{ij}x_{j}+c_{i}) \\\\\n",
    "\\frac{\\partial}{\\partial W_{ij}}\\epsilon_{\\lambda}(x) = ... = - Sigmoid(\\sum_{j}W_{ij}x_{j}+c_{i})x_{j}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the SGD scheme $\\lambda \\Longrightarrow \\lambda-\\eta\\nabla_{\\lambda} C_{\\lambda}$ where we pick out the intractable term in the gradient for discussion the sampling method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$<\\nabla_{\\lambda}\\epsilon_{\\lambda}(x)>_{p_{\\lambda}}=\\frac{1}{Z_{\\lambda}}\\sum_{x}e^{-\\epsilon_{\\lambda}(x)}\\nabla_{\\lambda}\\epsilon_{\\lambda}(x) \\\\\n",
    "\\approx \\frac{1}{m}\\sum_{i=1}^{m}\\nabla_{\\lambda}\\epsilon_{\\lambda}(x^{i})\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approximation is like the case which is almost always done by MC, like dealing with big integral or big summation over MC sampling points. Here the sampling points are {$x^{1}, x^{2}, ..., x^{i}, ..., x^{m}$} from $p_{\\lambda}(x)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS. Note that we use superscript for the data point and subscript for the component of a data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here due to the RBM's structure, we can do the sampling by a more specific method in MCMC called Gibbs sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gibbs sampling is going to sample $\\vec{x} = (x_{1},...,x_{j},...,x_{N})$ by selecting $x_{j}$ from the distribution $P(x_{j}|\\vec{x}_{-j})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $P(x_{j}|\\vec{x}_{-j})=P(x_{j}|x_{1},x_{2},...,x_{j-1},x_{j+1},...,x_{N})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can easily see the advantage RBM gives us. In RBM all components of $\\vec{x}$ are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, P is $p_{\\lambda}$. We make use of some properties of probability in the following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\lambda}(x_{j}|\\vec{x}_{-j},\\vec{h})=\\frac{p_{\\lambda}(x_{j},\\vec{x}_{-j},\\vec{h})}{p_{\\lambda}(\\vec{x}_{-j},\\vec{h})}=\\frac{p_{\\lambda}(x_{j},\\vec{x}_{-j}|\\vec{h})p_{\\lambda}(\\vec{h})}{p_{\\lambda}(\\vec{x}_{-j}|\\vec{h})p_{\\lambda}(\\vec{h})}=\\frac{p_{\\lambda}(x_{j},\\vec{x}_{-j}|\\vec{h})}{p_{\\lambda}(\\vec{x}_{-j}|\\vec{h})}=\\frac{p_{\\lambda}(x_{j}|\\vec{h})p_{\\lambda}(\\vec{x}_{-j}|\\vec{h})}{p_{\\lambda}(\\vec{x}_{-j}|\\vec{h})}=p_{\\lambda}(x_{j}|\\vec{h})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the first two equalities are from conditional probability properties and the last two are beneficial from RBM's structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to sample $x_{j}$ we only have to consider the condition of hidden units. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS. It's good to think of if it's the general rule for a graphic model. i.e., we can just consider the condition of units that are connected to the unit which we want to sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say we wanna sample particular value $x_{j}=1$, i.e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\lambda}(x_{j}=1|\\vec{h})=\\frac{p_{\\lambda}(x_{j}=1,\\vec{h})}{p_{\\lambda}(\\vec{h})}=\\frac{p_{\\lambda}(x_{j}=1,\\vec{h})}{\\sum_{\\vec{x}}p_{\\lambda}(\\vec{x},\\vec{h})}\n",
    "=\\frac{\\sum_{\\vec{x}_{-j}}p_{\\lambda}(x_{1},...,x_{j-1},x_{j}=1,x_{j+1},...,x_{N},\\vec{h})}{\\sum_{\\vec{x}}p_{\\lambda}(\\vec{x},\\vec{h})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we insert the RBM to this expression and obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\sum_{\\vec{x}_{-j}}e^{-b_{j}+\\sum_{i,j}-W_{ij}x_{i}h_{j}}e^{\\sum_{k\\neq j,j}-W_{kj}x_{k}h_{j}-\\sum_{k\\neq j}b_{k}x_{k}-\\sum_{i}c_{i}h_{i}}}{\\sum_{\\vec{x}}e^{\\sum_{i,j}-W_{ij}x_{i}h_{j}-\\sum_{i}b_{i}x_{i}-\\sum_{i}c_{i}h_{i}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the $e^{\\sum_{i}c_{i}h_{i}}$ term can be cancelled, thus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\sum_{\\vec{x}_{-j}}e^{-b_{j}+\\sum_{i,j}-W_{ij}x_{i}h_{j}}e^{\\sum_{k\\neq j,j}-W_{kj}x_{k}h_{j}-\\sum_{k\\neq j}b_{k}x_{k}}}{\\sum_{\\vec{x}}e^{\\sum_{i,j}-W_{ij}x_{i}h_{j}-\\sum_{i}b_{i}x_{i}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the sum and we have the result (have to check it for yourself)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\lambda}(x_{j}=1|\\vec{h})= \\frac{e^{-b_{j}+\\sum_{i}-W_{ij}h_{i}}\\prod_{k\\neq j}(1+e^{-\\sum_{i}W_{ik}h_{i}-b_{k}})}{\\prod_{j}(1+e^{\\sum_{i}-W_{ij}h_{i}-b_{j}})}= \\frac{e^{-b_{j}+\\sum_{i}-W_{ij}h_{i}}}{1+e^{-b_{j}+\\sum_{i}-W_{ij}h_{i}}} = Sigmoid(z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result gives a familiar procedure as FFNN that the input from previous layer is activated by an activation function and produce the output as an unit of the present layer. However, in RBM this activation function emerges naturally from the definition of RBM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to sample one visible unit given conditional probability of that unit with hidden units. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then thanks to the structure of RBM, units are independent intra-layer, we can sample the full visible unit by  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\lambda}(\\vec{x}|\\vec{h})= \\prod_{j}p_{\\lambda}(x_{j}|\\vec{h}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can do the same derivation as above for hidden units "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\lambda}(h_{i}=1|\\vec{x})= \\frac{e^{-c_{i}+\\sum_{j}-W_{ij}x_{j}}}{1+e^{-c_{i}+\\sum_{j}-W_{ij}x_{j}}} = Sigmoid(z')$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and of course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\lambda}(\\vec{h}|\\vec{x})= \\prod_{i}p_{\\lambda}(h_{i}|\\vec{x}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we have a scheme called Bloch-Gibbs sampling that enable us to update the full layer of units. (In contrary to the flipping way in MCMC updating of Ising spin configuration )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can go back to what we want to calculate by this sampling method, the negative phase of gradient of cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$<\\nabla_{\\lambda}\\epsilon_{\\lambda}(x)>_{p_{\\lambda}}\n",
    "\\approx \\frac{1}{m}\\sum_{i=1}^{m}\\nabla_{\\lambda}\\epsilon_{\\lambda}(x^{i})\n",
    "$  where {$x^{i}$} is sampled from $p_{\\lambda}(\\vec{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and in Metropolis language, the update proposal of $\\vec{x}\\rightarrow \\vec{x}'$ is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$g(\\vec{x}\\rightarrow \\vec{x}') = p_{\\lambda}(\\vec{x}'|\\vec{h})p_{\\lambda}(\\vec{h}|\\vec{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we complete the learning scheme of RBM by summarize those essential ingredients we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like FFNN, we minimize the cost function by updating our parameter via SGD at each training step. Everytime of update, we need the value of negative phase. The value of negative phase is determined via the Bloch-Gibbs sampling we just mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final technical difficulty to overcome is that the value of negative phase in the sampling is not efficiently determined because the time to reach equilibrium of the model probability is too long. (We sample one $\\vec{x}$ only when equilibrium is reached)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hinton proposed an alternative cost function called the contrastive divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$CD_{k} \\equiv KL(P||p_{\\lambda}) - KL(p^{k}_{\\lambda}||p_{\\lambda})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p^{k}_{\\lambda}$ is the model probability after k Gibbs samplings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\nabla_{\\lambda}CD_{k}=<\\nabla_{\\lambda}\\epsilon_{\\lambda}(x)>_{D} - <\\nabla_{\\lambda}\\epsilon_{\\lambda}(x)>_{p^{k}_{\\lambda}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we refresh our training scheme now: \n",
    "at every training step, we initialize one $\\vec{x}$ in Bloch-Gibbs sampling. After doing k Gibbs sampling, we compute the negative phase $<\\nabla_{\\lambda}\\epsilon_{\\lambda}(x)>_{p^{k}_{\\lambda}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we list the hyperparameters we can control in RBM training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of hidden units M (Expressive power)\n",
    "* Steps of CD k\n",
    "* Learning rate\n",
    "* Batch size\n",
    "* Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One training step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's exam training step in detail\n",
    "* 1. Select the batch of data\n",
    "* 2. Compute the positive phase $<\\nabla_{\\lambda}\\epsilon_{\\lambda}(x)>_{D}$\n",
    "* 3. Initialize Markov chain with data\n",
    "* 4. Run Gibbs sampling\n",
    "* 5. Compute the negative phase $<\\nabla_{\\lambda}\\epsilon_{\\lambda}(x)>_{samples}$\n",
    "* 6. Update the parameter $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further discussion of reconstruction of quantum states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The case we discuss for reconstructing quantum state is a closed and isolated system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is obtained from measurement, and everytime we measure, the quantum state collapses to one of the measurement state $|\\vec{\\sigma}>$. When we do it for N times, we get a dataset D={$|\\vec{\\sigma}^{1}>,|\\vec{\\sigma}^{2}>,...,|\\vec{\\sigma}^{N}>$}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider a more complex example but in 1D, tranverse field Ising model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H = -J\\sum_{j}\\sigma^{z}_{j}\\sigma^{z}_{j+1}-h\\sum_{j}\\sigma^{x}_{j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The importance of reconstructing quantum state is manifest in this case. Since in experiment we measure in one basis, say $\\sigma^{z}$, we know the expectation value of $\\sigma^{z}$ by just compute the sum depending on our data. But if we want to know the expectation value of $\\sigma^{x}$ based on our $\\sigma^{z}$ data, we'll need the wavefunction, i.e. quantum state on the $\\sigma^{z}$ basis. This can be illustrated by the following derivation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, if we want to compute some observables that can't be measured in experiment, unlike the case $\\sigma^{x}$ we just discussed which is just about cumbersome rearrangement of lab apparetus, we may want to know something like entanglement extropy. Quantum state reconstruction provides an unique way to capture that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
